# -*- coding: utf-8 -*-
"""Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YKdMIIHOez0-STLmwRTHGfBSr6OhFt2_
"""

from google.colab import drive
drive.mount('/content/drive')

"""# IMPORT LIBRARY"""

!pip install scikeras

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import string
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report


import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import RandomizedSearchCV
from scikeras.wrappers import KerasClassifier
from tensorflow.keras.optimizers import Adam, RMSprop

!pip install -q -U keras-tuner

"""# DATA UNDERSTANDING"""

true_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MLT submission 1/fake and real news dataset/True.csv')
fake_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MLT submission 1/fake and real news dataset/Fake.csv')

true_df['label'] = 1
fake_df['label'] = 0

df = pd.concat([true_df, fake_df], axis=0).sample(frac=1).reset_index(drop=True)
df.head(10)

# Visualisasi distribusi label
plt.figure(figsize=(6,4))
sns.countplot(x='label', data=df, palette='viridis')
plt.title('Distribusi Label Berita (Fake vs Real)', fontsize=14)
plt.xticks([0, 1], ['Fake (0)', 'Real (1)'])
plt.xlabel('Label')
plt.ylabel('Jumlah Data')
plt.show()

print(df['label'].value_counts())

df.info()

df.isnull().sum()

df['text'].duplicated().sum()

df.describe()

"""**Insight:**


*   Dataset terdiri dari 2 file yang berbeda yaitu True.csv dan Fake.csv yang nama masing masing file sesuai dengan kelas aktualnya
*   Jumlah dataset awal adalah 44898 data
*   Dataset memiliki 4 kolom bawaan, yaitu title, text, subject dan date. seluruh kolom bertipe data String
*   Dataset digabungkan menjadi satu dataframe dengan tambahan kolom label dengan tipe data integer yaitu 0 untuk fake dan 1 untuk true
*   Distribusi label terdiri dari 23481 label fake dan 21417 label true
*   Dataset memiliki 6252 data duplikat

# DATA PREPARATION
"""

def clean_text(text):
    text = text.lower()
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub(r'\n', '', text)
    return text

df['text'] = df['text'].apply(clean_text)

df = df.drop_duplicates(subset='text', keep='first')
df['text'].duplicated().sum()

max_words = 5000
max_len = 500

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(df['text'])
sequences = tokenizer.texts_to_sequences(df['text'])
X = pad_sequences(sequences, maxlen=max_len)
y = df['label'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ukuran total data
print("Total data:", len(X))

# Ukuran test
print("Test data:", len(X_test))

# Ukuran train sebelum di-split validation
print("Train total (before validation split):", len(X_train))

# Ukuran validation (20% dari train)
val_size = int(0.2 * len(X_train))
print("Validation data (from train):", val_size)

# Ukuran train sesungguhnya (80% dari train)
print("Final training data:", len(X_train) - val_size)

"""**Insight:**


*   Dilakukan cleansing data untuk kolom text menggunakan lowering case, menghapus teks didalam tanda kurung siku, menghapus URL, menghapus tag HTML, menghapus tanda baca, dan membuat teks menjadi satu baris
*   dilakukan penghapusan data yang duplikat karena sebelumnya terdeteksi adanya data yang duplikat
*   dilakukan tokenisasi terhadap data teks
*   dilakukan split dataset dengan data training 80%, validation 10% dan test 10%

# MODELING
"""

early_stop = EarlyStopping(
    monitor='val_loss',     # Pantau loss validasi
    patience=3,             # Stop jika tidak membaik selama 3 epoch
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',     # Turunkan LR jika val_loss stagnan
    factor=0.5,             # Turunkan LR sebesar 50%
    patience=2,             # Setelah 2 epoch tanpa perbaikan
    min_lr=1e-6             # Minimal LR
)

model = Sequential()
model.add(Embedding(max_words, 128, input_length=max_len))
model.add(LSTM(64, return_sequences=False))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stop, reduce_lr])

"""**Insight:**


*   Menggunakan Early Stopping dalam proses pemodelan untuk menghindari overfitting dan menghemat waktu pelatihan
*   Menggunakan Reduce Learning Rate untuk mengadaptasi learning rate saat model stagnan untuk hasil yang lebih optimal
*   Arsitektur model yang digunakan terdiri dari empat lapisan utama yang dirancang untuk mendeteksi berita palsu berbasis teks. Model dimulai dengan lapisan Embedding yang mengubah setiap kata menjadi vektor berdimensi 128 untuk merepresentasikan makna kata dalam bentuk numerik, dengan panjang input sesuai jumlah token maksimum (max_len). Selanjutnya, vektor tersebut diproses oleh LSTM (Long Short-Term Memory) dengan 64 unit yang mampu menangkap hubungan kontekstual antar kata dalam urutan teks. Setelah itu, diterapkan Dropout sebesar 0.5 untuk mencegah overfitting dengan menonaktifkan sebagian neuron secara acak selama pelatihan. Terakhir, output diarahkan ke Dense layer dengan 1 neuron dan fungsi aktivasi sigmoid untuk menghasilkan probabilitas klasifikasi biner, yaitu apakah suatu berita tergolong palsu atau nyata.
*    Model dilatih menggunakan fungsi loss binary crossentropy dan optimizer Adam selama maksimal 100 epoch dengan batch size 64. Untuk mencegah overfitting dan mempercepat pelatihan, digunakan EarlyStopping yang menghentikan training jika val_loss tidak membaik selama 3 epoch. Selain itu, ReduceLROnPlateau menurunkan learning rate sebesar 50% jika val_loss stagnan selama 2 epoch. Sebanyak 20% data training digunakan sebagai validasi, sehingga kinerja model dapat dipantau dan disesuaikan secara dinamis selama proses pelatihan.

# EVALUATION
"""

# Prediksi hasil (nilai probabilitas sigmoid)
y_pred_prob = model.predict(X_test)

# Konversi ke 0 dan 1
y_pred = (y_pred_prob > 0.5).astype(int)

print("Accuracy: {:.4f}".format(accuracy_score(y_test, y_pred)))
print("Precision: {:.4f}".format(precision_score(y_test, y_pred)))
print("Recall: {:.4f}".format(recall_score(y_test, y_pred)))
print("F1 Score: {:.4f}".format(f1_score(y_test, y_pred)))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred, target_names=["Fake", "Real"]))

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Fake", "Real"], yticklabels=["Fake", "Real"])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""**insight:**


*   Accuracy 0.9839 = Model secara keseluruhan memprediksi dengan benar sebanyak 98.39%.
*   Precision 0.9729 = Dari seluruh berita yang diprediksi fake, 97.29% benar-benar fake.
*   Recall 0.9920 = Dari seluruh berita yang benar-benar fake, 99.20% berhasil dideteksi model.
*   F1 Score 0.9855 = Rata-rata harmonis antara precision dan recall, menunjukkan keseimbangan performa.
*   Classification report menunjukkan performa model dalam mendeteksi berita palsu dan asli berdasarkan metrik precision, recall, dan F1-score. Untuk kelas "Fake", model mencapai precision sebesar 0.89, artinya 89% dari prediksi berita palsu memang benar palsu, dengan recall sebesar 0.97 yang menunjukkan bahwa 97% dari semua berita palsu berhasil terdeteksi. Sementara untuk kelas "Real", precision dan recall sangat tinggi, masing-masing sebesar 0.98 dan 0.99, menandakan bahwa model sangat akurat dan sensitif dalam mengenali berita asli. Nilai F1-score untuk kedua kelas pun tinggi, yaitu 0.93 untuk Fake dan 0.98 untuk Real, yang mengindikasikan performa model sangat seimbang. Rata-rata makro dan tertimbang dari ketiga metrik tersebut juga sebesar 0.98, menunjukkan bahwa model bekerja sangat baik secara keseluruhan dalam menangani kedua kelas.
*   Confusion matrix menunjukkan bahwa model mampu mengklasifikasikan berita palsu dan asli dengan sangat baik. Dari total data uji, terdapat 3.368 berita palsu yang berhasil diklasifikasikan dengan benar sebagai palsu (true positive), dan hanya 90 berita palsu yang salah dikenali sebagai berita asli (false negative). Sementara itu, sebanyak 4.227 berita asli diklasifikasikan dengan benar (true negative), dan hanya 34 berita asli yang keliru terdeteksi sebagai palsu (false positive). Hasil ini menunjukkan bahwa model memiliki tingkat kesalahan yang sangat rendah dan sangat efektif dalam mengenali kedua kategori berita, dengan kesalahan terbanyak berasal dari berita palsu yang lolos sebagai berita asli.



"""